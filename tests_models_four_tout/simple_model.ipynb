{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#création d'un premier model très simple (tfidf , stop word etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupération petit dataset (15k rows) d'entrainement et de test\n",
    "#df = pd.read_csv('../set_train_simple/first_train_test15k.csv')\n",
    "df = pd.read_csv('../set_train_simple/eqtype_train_test15k_.csv')\n",
    "#division du set en 2 train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df.copy(), test_size=(1/3), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "people       3000\n",
       "satirique    3000\n",
       "actu         3000\n",
       "science      3000\n",
       "parodique    3000\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['titre']= train['titre'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_tok1 = []\n",
    "from nltk import word_tokenize\n",
    "for titre in train['titre']:\n",
    "    words = word_tokenize(titre)\n",
    "    liste_tok1.append(words)\n",
    "train['tokken1']=liste_tok1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.7563"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nombre de tokken en moy par titre tok1\n",
    "len([item for sublist in train['tokken1'] for item in sublist])/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21105"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taille du vocabulaire+ tok1\n",
    "len(set([item for sublist in train['tokken1'] for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re \n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+') \n",
    "\n",
    "liste_tok2 = []\n",
    "for titre in train['titre']:\n",
    "\n",
    "\n",
    "    words = tokenizer.tokenize(re.sub('[0-9]+', '', titre.lower()))\n",
    "\n",
    "    #new_words = list( set(words) - stop_words)   #=>\n",
    "    new_words = [word for word in words if word not in stop_words]\n",
    "    liste_tok2.append(new_words)\n",
    "    \n",
    "#imdb_data['tokkens'] = liste_tok\n",
    "train['tokken2']=liste_tok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.5277"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nombre de tokken en moy par titre tok2\n",
    "len([item for sublist in train['tokken2'] for item in sublist])/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17103"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taille du vocabulaire tok2\n",
    "len(set([item for sublist in train['tokken2'] for item in sublist]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulaire = list(set([item for sublist in train['tokken2'] for item in sublist]))\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#sur corpus train\n",
    "corpus = list(train['titre'])\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulaire)),\n",
    "                 ('tfid', TfidfTransformer())]).fit(corpus)\n",
    "#matrice entrainement\n",
    "tab = pipe['count'].transform(corpus).toarray()\n",
    "df_mod = pd.DataFrame(tab , columns = vocabulaire)\n",
    "#gestion memoire\n",
    "del pipe\n",
    "del tab\n",
    "del corpus\n",
    "\n",
    "# #sur corpus test # vocabulaire reste celui du train \n",
    "# corpus_test = list(test['titre'])\n",
    "# pipe_test = Pipeline([('count', CountVectorizer(vocabulary=vocabulaire)),\n",
    "#                  ('tfid', TfidfTransformer())]).fit(corpus_test)\n",
    "# #matrice test\n",
    "# tab_test = pipe['count'].transform(corpus).toarray()\n",
    "# df_mod_test = pd.DataFrame(tab_test , columns = vocabulaire)\n",
    "# #gestion memoire\n",
    "# del pipe_test\n",
    "# del tab_test\n",
    "# del corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    0\n",
       "9998    0\n",
       "9999    0\n",
       "Name: ethnique, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod['ethnique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "tab = pipe['count'].transform(corpus).toarray()\n",
    "df_mod = pd.DataFrame(tab , columns = vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vittel</th>\n",
       "      <th>insuffisances</th>\n",
       "      <th>atteinte</th>\n",
       "      <th>iraniens</th>\n",
       "      <th>autoconférence</th>\n",
       "      <th>fake</th>\n",
       "      <th>djokovic</th>\n",
       "      <th>klimt</th>\n",
       "      <th>complexée</th>\n",
       "      <th>informations</th>\n",
       "      <th>...</th>\n",
       "      <th>ep</th>\n",
       "      <th>religions</th>\n",
       "      <th>mosaïques</th>\n",
       "      <th>covit</th>\n",
       "      <th>bastille</th>\n",
       "      <th>elysée</th>\n",
       "      <th>infos</th>\n",
       "      <th>brunes</th>\n",
       "      <th>absurdes</th>\n",
       "      <th>proférer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 17103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      vittel  insuffisances  atteinte  iraniens  autoconférence  fake  \\\n",
       "0          0              0         0         0               0     0   \n",
       "1          0              0         0         0               0     0   \n",
       "2          0              0         0         0               0     0   \n",
       "3          0              0         0         0               0     0   \n",
       "4          0              0         0         0               0     0   \n",
       "...      ...            ...       ...       ...             ...   ...   \n",
       "9995       0              0         0         0               0     0   \n",
       "9996       0              0         0         0               0     0   \n",
       "9997       0              0         0         0               0     0   \n",
       "9998       0              0         0         0               0     0   \n",
       "9999       0              0         0         0               0     0   \n",
       "\n",
       "      djokovic  klimt  complexée  informations  ...  ep  religions  mosaïques  \\\n",
       "0            0      0          0             0  ...   0          0          0   \n",
       "1            0      0          0             0  ...   0          0          0   \n",
       "2            0      0          0             0  ...   0          0          0   \n",
       "3            0      0          0             0  ...   0          0          0   \n",
       "4            0      0          0             0  ...   0          0          0   \n",
       "...        ...    ...        ...           ...  ...  ..        ...        ...   \n",
       "9995         0      0          0             0  ...   0          0          0   \n",
       "9996         0      0          0             0  ...   0          0          0   \n",
       "9997         0      0          0             0  ...   0          0          0   \n",
       "9998         0      0          0             0  ...   0          0          0   \n",
       "9999         0      0          0             0  ...   0          0          0   \n",
       "\n",
       "      covit  bastille  elysée  infos  brunes  absurdes  proférer  \n",
       "0         0         0       0      0       0         0         0  \n",
       "1         0         0       0      0       0         0         0  \n",
       "2         0         0       0      0       0         0         0  \n",
       "3         0         0       0      0       0         0         0  \n",
       "4         0         0       0      0       0         0         0  \n",
       "...     ...       ...     ...    ...     ...       ...       ...  \n",
       "9995      0         0       0      0       0         0         0  \n",
       "9996      0         0       0      0       0         0         0  \n",
       "9997      0         0       0      0       0         0         0  \n",
       "9998      0         0       0      0       0         0         0  \n",
       "9999      0         0       0      0       0         0         0  \n",
       "\n",
       "[10000 rows x 17103 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "satirique    2023\n",
       "science      2019\n",
       "people       2006\n",
       "parodique    1986\n",
       "actu         1966\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.LabelEncoder().fit(train['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actu', 'parodique', 'people', 'satirique', 'science'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actu', 'parodique', 'people', 'satirique', 'science'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.inverse_transform([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=encoder.transform(train['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, random_state=8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X=df_mod\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=5, random_state=8)\n",
    "clf.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_train = confusion_matrix(Y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4707\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y,y_pred_train)\n",
    "print('Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 131,   93,   65, 1410,  267],\n",
       "       [  28,  659,  125,  953,  221],\n",
       "       [   1,   86, 1249,  590,   80],\n",
       "       [   2,   45,   40, 1803,  133],\n",
       "       [  11,   47,   29, 1067,  865]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "clf = CategoricalNB()\n",
    "clf.fit(X, Y)\n",
    "\n",
    "\n",
    "y_pred_train = clf.predict(X)\n",
    "\n",
    "cm_train = confusion_matrix(Y, y_pred_train)\n",
    "\n",
    "accuracy = metrics.accuracy_score(Y,y_pred_train)\n",
    "print('Accuracy:',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1461,   33,   30,  323,  119],\n",
       "       [  47, 1684,   50,  134,   71],\n",
       "       [  16,   68, 1856,   57,    9],\n",
       "       [   5,    7,    4, 1988,   19],\n",
       "       [  34,   13,    7,  139, 1826]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score: 0.881356108341171\n"
     ]
    }
   ],
   "source": [
    "f1_score = metrics.f1_score(Y,y_pred_train, average='macro')\n",
    "print('f1_score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avec test\n",
    "corpus = list(test['titre'])\n",
    "pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulaire)),\n",
    "                 ('tfid', TfidfTransformer())]).fit(corpus)\n",
    "\n",
    "tab = pipe['count'].transform(corpus).toarray()\n",
    "df_mod = pd.DataFrame(tab , columns = vocabulaire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
